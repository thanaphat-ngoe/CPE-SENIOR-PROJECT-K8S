import time
import datetime
import subprocess
import numpy as np
import joblib
import warnings  
from tensorflow.keras.models import load_model

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ß‡πâ
from DecisionEngineV2 import DecisionEngine
from node_manager import NodeManager

warnings.filterwarnings("ignore", category=UserWarning, module='sklearn')

# ==========================================
# 1. ‚öôÔ∏è CONFIGURATION
# ==========================================
MODEL_PATH = 'best_single_var_model.keras'  # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà (1 Feature)
SCALER_PATH = 'scaler.pkl'                  # Scaler ‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà
WINDOW_SIZE = 30                            # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô (‡∏ñ‡πâ‡∏≤‡πÄ‡∏ó‡∏£‡∏ô 30 ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà 30)

NODES = {
    'master': 'aj-aung-k8s-master',
    'worker1': 'aj-aung-k8s-worker1',
    'worker2': 'aj-aung-k8s-worker2'
}

AVAILABLE_WORKERS = ["10.35.29.109", "10.35.29.110"] # IP ‡∏Ç‡∏≠‡∏á Worker1, Worker2

# ==========================================
# 2. üõ†Ô∏è HELPER FUNCTIONS (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• K8s)
# ==========================================
def parse_k8s_value(value_str):
    """ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å K8s ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢ Cores """
    if not value_str: return 0.0
    value_str = str(value_str).strip()
    try:
        if value_str.endswith('m'):
            return float(value_str.replace('m', '')) / 1000.0
        return float(value_str)
    except:
        return 0.0

def run_cmd(cmd):
    try:
        return subprocess.check_output(cmd, shell=True, stderr=subprocess.DEVNULL).decode('utf-8').strip()
    except:
        return ""

def fetch_realtime_data():
    total_cpu_req = 0.0
    
    # --- ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏Ñ‡∏¥‡∏î % ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ù‡∏±‡πà‡∏á Worker ---
    worker_cpu_usage = 0.0
    worker_cpu_cap = 0.0
    active_workers = 0

    for key, node in NODES.items():
        status_out = run_cmd(f"kubectl get node {node} --no-headers | awk '{{print $2}}'")
        if "Ready" in status_out:
            
            # 1. ‡∏î‡∏∂‡∏á CPU Request ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI)
            out_req = run_cmd(f"kubectl describe node {node} | grep -A 5 'Allocated resources' | tail -n 2")
            try:
                cpu_req = parse_k8s_value(out_req.splitlines()[0].split()[1])
                total_cpu_req += cpu_req
            except: pass

            # 2. ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Worker ‡∏°‡∏≤‡∏Ñ‡∏¥‡∏î % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
            if key.startswith('worker'):
                active_workers += 1
                
                # ‡πÄ‡∏Å‡πá‡∏ö Capacity ‡∏Ç‡∏≠‡∏á Worker
                out_cap = run_cmd(f"kubectl get node {node} -o jsonpath='{{.status.capacity.cpu}}'")
                worker_cpu_cap += parse_k8s_value(out_cap)

                # ‡πÄ‡∏Å‡πá‡∏ö Usage ‡∏Ç‡∏≠‡∏á Worker
                out_usage = run_cmd(f"kubectl top node {node} --no-headers | awk '{{print $2}}'")
                worker_cpu_usage += parse_k8s_value(out_usage)

    # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % CPU Usage ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (Guardrail ‡∏Ç‡∏≤‡∏•‡∏á) ‡∏à‡∏≤‡∏Å Worker ‡∏•‡πâ‡∏ß‡∏ô‡πÜ!
    current_cpu_percent = 0.0
    if worker_cpu_cap > 0:
        current_cpu_percent = (worker_cpu_usage / worker_cpu_cap) * 100

    # 4. ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Pending Pods
    pending_count = 0
    try:
        pending_cmd = "kubectl get pods -A --field-selector=status.phase=Pending --no-headers | wc -l"
        pending_count = int(run_cmd(pending_cmd))
    except: pass

    return total_cpu_req, active_workers, pending_count, current_cpu_percent
    """ 
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 4 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
    1. total_cpu_req (‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI)
    2. current_workers (‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ DecisionEngine)
    3. pending_pods (‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ DecisionEngine)
    4. current_cpu_usage (‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ DecisionEngine)
    """
    total_cpu_req = 0.0
    total_cpu_usage = 0.0
    total_cpu_cap = 0.0
    active_workers = 0

    # 1. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏µ‡∏•‡∏∞ Node
    for key, node in NODES.items():
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Node ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏´‡∏°? (‡∏î‡∏π‡∏à‡∏≤‡∏Å Status Ready)
        status_out = run_cmd(f"kubectl get node {node} --no-headers | awk '{{print $2}}'")
        if "Ready" in status_out:
            if key.startswith('worker'):
                active_workers += 1

            # ‡∏î‡∏∂‡∏á Cap (Capacity)
            out_cap = run_cmd(f"kubectl get node {node} -o jsonpath='{{.status.capacity.cpu}}'")
            total_cpu_cap += parse_k8s_value(out_cap)

            # ‡∏î‡∏∂‡∏á Req (CPU Requests) - ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI !
            out_req = run_cmd(f"kubectl describe node {node} | grep -A 5 'Allocated resources' | tail -n 2")
            try:
                cpu_req = parse_k8s_value(out_req.splitlines()[0].split()[1])
                total_cpu_req += cpu_req
            except: pass

            # ‡∏î‡∏∂‡∏á Usage (CPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ)
            out_usage = run_cmd(f"kubectl top node {node} --no-headers | awk '{{print $2}}'")
            total_cpu_usage += parse_k8s_value(out_usage)

    # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % CPU Usage ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (Guardrail ‡∏Ç‡∏≤‡∏•‡∏á)
    current_cpu_percent = 0.0
    if total_cpu_cap > 0:
        current_cpu_percent = (total_cpu_usage / total_cpu_cap) * 100

    # 3. ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Pending Pods
    pending_count = 0
    try:
        pending_cmd = "kubectl get pods -A --field-selector=status.phase=Pending --no-headers | wc -l"
        pending_count = int(run_cmd(pending_cmd))
    except: pass

    return total_cpu_req, active_workers, pending_count, current_cpu_percent

# ==========================================
# 3. üöÄ MAIN SYSTEM LOOP
# ==========================================
print("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏∞‡∏ö‡∏ö Predictive Autoscaling (v2.0)...")
try:
    model = load_model(MODEL_PATH, compile=False)
    scaler = joblib.load(SCALER_PATH)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏°‡∏≠‡∏á ‡πÅ‡∏•‡∏∞ ‡∏°‡∏∑‡∏≠
    decision_engine = DecisionEngine(cores_per_node=4.0, max_workers=2, min_workers=1)
    node_bot = NodeManager()
    
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î AI ‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
except Exception as e:
    print(f"‚ùå Error ‡∏ï‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}")
    exit()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ CPU Request 30 ‡∏ô‡∏≤‡∏ó‡∏µ (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI)
history_buffer = []

print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ Monitor Cluster (‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö {WINDOW_SIZE} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)...\n")

while True:
    try:
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        
        # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏î‡πÜ ‡∏à‡∏≤‡∏Å Cluster
        cpu_req, current_workers, pending_pods, cpu_usage_pct = fetch_realtime_data()
        
        # 2. ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏•‡∏á Buffer
        history_buffer.append([cpu_req]) # ‡πÉ‡∏™‡πà‡πÄ‡∏õ‡πá‡∏ô List ‡∏ã‡πâ‡∏≠‡∏ô List ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á 2D
        if len(history_buffer) > WINDOW_SIZE:
            history_buffer.pop(0)

        # 3. ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡∏™‡∏∞‡∏™‡∏°‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
        if len(history_buffer) < WINDOW_SIZE:
            print(f"[{timestamp}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏∞‡∏™‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ CPU Request... ({len(history_buffer)}/{WINDOW_SIZE}) | Req ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ: {cpu_req:.2f} Cores", end='\r')
            time.sleep(1) # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÜ 1 ‡∏ô‡∏≤‡∏ó‡∏µ 
            continue

        print(f"\n[{timestamp}] " + "="*45)
        print(f"üìä [Status] Workers: {current_workers} | CPU Usage: {cpu_usage_pct:.1f}% | Pending Pods: {pending_pods}")

        # 4. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Array 2D ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤ Scaler
        raw_array = np.array(history_buffer) 
        scaled_array = scaler.transform(raw_array)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏á‡πÄ‡∏õ‡πá‡∏ô 3D (1 batch, 30 timesteps, 1 feature) ‡πÉ‡∏´‡πâ LSTM
        X_input = scaled_array.reshape(1, WINDOW_SIZE, 1)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
        pred_scaled = model.predict(X_input, verbose=0)
        predicted_cores = scaler.inverse_transform(pred_scaled)[0][0]
        
        print(f"üîÆ [AI Predict] CPU Request ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {cpu_req:.2f} ‚û°Ô∏è ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°: {predicted_cores:.2f} Cores")

        # 5. ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Decision Engine ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à!
        action, reason = decision_engine.decide(
            predicted_cores=predicted_cores,
            current_workers=current_workers,
            pending_pods=pending_pods,
            current_cpu_usage=cpu_usage_pct
        )
        
        print(f"ü§ñ [Decision]: {action}")
        print(f"‚ÑπÔ∏è [Reason]  : {reason}")
        
        # 6. ‡∏™‡∏±‡πà‡∏á‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥ (Actuator)
        if action == "SCALE_OUT":
            # ‡∏´‡∏≤ IP ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤ current_workers = 1 ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡∏¥‡∏î W1 ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß, ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏¥‡∏î W2)
            if current_workers < len(AVAILABLE_WORKERS):
                target_ip = AVAILABLE_WORKERS[current_workers]
                print(f"üöÄ ACTION: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {target_ip} ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô...")
                node_bot.scale_up(target_ip)
            
        elif action == "SCALE_IN":
            # ‡πÄ‡∏ï‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏≠‡∏≠‡∏Å
            if current_workers > 0:
                target_ip = AVAILABLE_WORKERS[current_workers - 1]
                print(f"üîª ACTION: ‡πÇ‡∏´‡∏•‡∏î‡∏ô‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {target_ip}...")
                node_bot.scale_down(target_ip)

        print("="*58)
        
        # ‡∏û‡∏±‡∏Å‡∏£‡∏≠ 1 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏´‡∏ô‡πà‡∏ß‡∏á 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏™‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö)
        time.sleep(1)

    except KeyboardInterrupt:
        print("\nüõë ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Ctrl+C)")
        break
    except Exception as e:
        print(f"\n‚ùå Error ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏±‡∏ô‡∏•‡∏π‡∏õ: {e}")
        time.sleep(5)
